
``Model-based software engineering'' is where teams use high-level abstractions to guide discussion, code generation, or validation. Unlike document-centric approaches, models serve as blueprints for developers to write code, and tools automate much of the noncreative work (which translates to gains in productivity and quality). But as models grow larger, it becomes harder to find options that are most useful and most acceptable to stakeholders.

% We conjecture that    (a)
% \underline{\bf if automated tools    understood stakeholder preferences and  goals} then  ~those tools can   (b)~
% \underline{\bf help  development teams     explore and mature their models, faster
% with   less cognitive effort}.


% Model-based software engineering is a nuanced craft, involving the intricate exploration of many options. Some models are very complex
% and  can generate an overwhelming array of possibilities. This complexity poses a challenge in identifying options that not only align with the needs of all stakeholders but also stand out as the most valuable and widely accepted among them.

%Requirements engineering is the art of exploring a large space of options. But some requirement models are very complex and can generate too many options.This makes it hard to  find options that are most useful and most acceptable to all stakeholders

 If automated tools understood stakeholder
preferences and goals, can they help us mature our models faster? Perhaps so. To check, we propose {\IT}, a  human-in-the-loop AI tool
that learns preferences and goals from stakeholder’s textual statements.  {\IT}'s AI tools will use large language models to explore that text to infer human preferences. Other AI tools in {\IT}  will then apply human-in-the-loop multi-objective swarm optimization to
help humans find the most preferred solutions which best satisfy domain constraints.

 {\IT}   will be a success if (a)~in less time, more humans can find, explore, assess, and agree on the most important model options; and  explore and  assess and agree on the most
important model options;  and
(b)~the agreed-upon options actually improve system performance. For example,
if an operator of a drone fleet focuses on the issues raised by \IT, they
are faster at detecting and mitigating danger scenarios.


To facilitate open science, all the scripts, models, and data used in this project will be stored on GitHub and will be freely available to researchers and industrial practitioners.

%TIM: Software engineering has been so successful that now we struggle, and often fail, to understand  the increasingly complex models we are building.  Enabling humans to exploring all the important potential behaviours of a software model is an open and serious issue.  Regrettably, there are   many  examples where human oversight missed   important software  properties.

%To forge an effective partnership, humans and software need to understand each other's strengths and limitations.  For example, interactive search-based SE tools (iSBSE)  work well when taking advice from one person but have issues dealing with all the different advice that comes from large teams Accordingly,  we propose extending iSBSE with particle-swarm optimization and generative transformer models to  handle teams; specifically: (1)~debates and disagreements between team members;(2)~team members with a established track-record of offering good/bad advice; and (3)~team members that (consciously   or unconsciously) offer advice that lead to discriminatory models.
 


%Our new system   will be used to better police policy decisions made by software systems. To facilitate open science, all the scripts, models, and data used in this data will be stored on Github ad be freely available to researchers and industrial practitioners.

 

\noindent{\bf  INTELLECTUAL  MERIT}


 
The study distinguishes itself by prioritizing collective team decision-making and seamlessly integrating symbolic and sub-symbolic models, offering a rich, multidimensional approach absent in current research paradigms. Its transformative nature promises to revolutionize software design decision-making. 

\noindent{\bf BROADER IMPACTS}

 Bringing humans in the loop of the decision-making process for AI-based systems is an important area to explore in SE research. This could help to mold models better to human processes and potentially make them more explainable or interpretable.
 
 Given the rapid rise of AI-assisted tools for developers, exploring work that more closely involves human feedback will be an important line of work, and one that bears fruit for various SE tasks.


 NC  State’s  Computer  Science  department  has  a  long  tradition  of  studying research issues related to gender bias,  barriers faced by women, and methods for broadening participation    in  the  context  of  software  engineering. 
This work will continue that tradition.
Curriculum  and lecture notes of the graduate SE classes (taught by PI Menzies
and  co-PI Sandeep Kuttal ) will be revised from this work. Funds from this work will be used to support students attending the Grace Hopper conference, and the Richard Tapia Celebration  of Diversity in Computing. Furthermore,  a (small) portion of this grant would be allocated to support Broadening Participation in Computing (BPC) work.   PI  Menzies and  co-PI Kuttal are  members  of  their  department’s Broadening Participation Committee (BPC) which actively seeks to:  (a)~Understand what factors make computer science more (or less) attractive to underrepresented groups; (b)~Educate faculty, staff, and students on how different behaviors affect diversity, quality, and inclusiveness; (c)~Increase the percent of students who identify as women, and (d)~Evaluate the success of this BPC team in broadening participation.  